"use strict";(self.webpackChunklangchain=self.webpackChunklangchain||[]).push([[9119],{3905:(e,t,r)=>{r.d(t,{Zo:()=>d,kt:()=>m});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function s(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?s(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},s=Object.keys(e);for(n=0;n<s.length;n++)r=s[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)r=s[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var l=n.createContext({}),c=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),p=c(r),g=a,m=p["".concat(l,".").concat(g)]||p[g]||u[g]||s;return r?n.createElement(m,o(o({ref:t},d),{},{components:r})):n.createElement(m,o({ref:t},d))}));function m(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var s=r.length,o=new Array(s);o[0]=g;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[p]="string"==typeof e?e:a,o[1]=i;for(var c=2;c<s;c++)o[c]=r[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}g.displayName="MDXCreateElement"},5052:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});var n=r(7462),a=(r(7294),r(3905));const s={sidebar_position:2},o="Concepts",i={unversionedId:"Getting started/concepts",id:"Getting started/concepts",title:"Concepts",description:"Processors",source:"@site/docs/Getting started/concepts.md",sourceDirName:"Getting started",slug:"/Getting started/concepts",permalink:"/langchainrb-docs/docs/Getting started/concepts",draft:!1,editUrl:"https://github.com/alchaplinsky/lcrb/tree/main/packages/create-docusaurus/templates/shared/docs/Getting started/concepts.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Installation",permalink:"/langchainrb-docs/docs/Getting started/installation"},next:{title:"LLMs",permalink:"/langchainrb-docs/docs/category/llms"}},l={},c=[{value:"Processors",id:"processors",level:2},{value:"Chunkers",id:"chunkers",level:2},{value:"Prompts",id:"prompts",level:2},{value:"Large Language Models (LLMs)",id:"large-language-models-llms",level:2},{value:"Vectorsearch Databases",id:"vectorsearch-databases",level:2},{value:"Embedding",id:"embedding",level:3},{value:"Logging",id:"logging",level:2}],d={toc:c},p="wrapper";function u(e){let{components:t,...r}=e;return(0,a.kt)(p,(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"concepts"},"Concepts"),(0,a.kt)("h2",{id:"processors"},"Processors"),(0,a.kt)("p",null,"Processors load and parse/process various data types such as CSVs, PDFs, Word documents, HTML pages, and others."),(0,a.kt)("h2",{id:"chunkers"},"Chunkers"),(0,a.kt)("p",null,"Chunkers split data based on various available options such as delimeters, chunk sizes or custom-defined functions. Chunkers are used when data needs to be split up before being imported in vector databases."),(0,a.kt)("h2",{id:"prompts"},"Prompts"),(0,a.kt)("p",null,"Prompts are structured inputs to the LLMs. Prompts provide instructions, context and other user input that LLMs use to generate responses."),(0,a.kt)("h2",{id:"large-language-models-llms"},"Large Language Models (LLMs)"),(0,a.kt)("p",null,"LLM is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning."),(0,a.kt)("h2",{id:"vectorsearch-databases"},"Vectorsearch Databases"),(0,a.kt)("p",null,"Vector database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of features or attributes. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data."),(0,a.kt)("h3",{id:"embedding"},"Embedding"),(0,a.kt)("p",null,"Word embedding or word vector is an approach with which we represent documents and words. It is defined as a numeric vector input that allows words with similar meanings to have the same representation. It can approximate meaning and represent a word in a lower dimensional space."),(0,a.kt)("h2",{id:"logging"},"Logging"),(0,a.kt)("p",null,"LangChain.rb uses standard logging mechanisms and defaults to :debug level. Most messages are at info level, but we will add debug or warn statements as needed. To show all log messages:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ruby"},"Langchain.logger.level = :info\n")))}u.isMDXComponent=!0}}]);